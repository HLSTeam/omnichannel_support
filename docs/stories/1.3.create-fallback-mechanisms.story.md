# Story 1.3: Create fallback mechanisms and error handling

**Epic:** 1 - AI Core Infrastructure  
**Story:** 1.3  
**Status:** Draft  
**Priority:** High  
**Estimate:** 3 days  
**Assigned To:** TBD  

---

## Story

**As a** system administrator,  
**I want** the AI service to have robust fallback mechanisms and error handling,  
**so that** the system continues to function even when AI analysis fails or confidence is low.

---

## Acceptance Criteria

1. **Rule-Based Fallback System**
   - System falls back to rule-based analysis when AI confidence <50%
   - Rule-based patterns cover all 5-10 intent types
   - Fallback system maintains >60% accuracy for basic requests
   - Fallback usage is logged and monitored

2. **Error Handling & Resilience**
   - Service gracefully handles Ollama unavailability
   - Network timeouts and connection errors are handled
   - Invalid input is validated and rejected appropriately
   - Error messages are user-friendly and actionable

3. **Service Health Monitoring**
   - Health check endpoint reports service status
   - Ollama service availability is monitored
   - Performance metrics are tracked and logged
   - Alerts are triggered for critical failures

4. **Graceful Degradation**
   - System continues to function with reduced AI capabilities
   - Fallback mechanisms are automatically activated
   - User experience is maintained during AI outages
   - Recovery is automatic when AI service is restored

5. **Comprehensive Logging**
   - All AI operations are logged with appropriate detail
   - Fallback usage is tracked and reported
   - Error conditions are logged with context
   - Performance metrics are captured for analysis

---

## Tasks / Subtasks

- [ ] **Task 1 (AC: 1):** Implement rule-based fallback system
  - [ ] Create rule-based intent analyzer
  - [ ] Implement pattern matching for all intent types
  - [ ] Add fallback confidence scoring
  - [ ] Create fallback decision logic

- [ ] **Task 2 (AC: 2):** Build comprehensive error handling
  - [ ] Implement try-catch blocks in all AI operations
  - [ ] Add timeout handling for Ollama requests
  - [ ] Create input validation middleware
  - [ ] Implement user-friendly error responses

- [ ] **Task 3 (AC: 3):** Add service health monitoring
  - [ ] Enhance health check endpoint
  - [ ] Implement Ollama service monitoring
  - [ ] Add performance metrics collection
  - [ ] Create alerting system for failures

- [ ] **Task 4 (AC: 4):** Implement graceful degradation
  - [ ] Create service state management
  - [ ] Implement automatic fallback activation
  - [ ] Add service recovery logic
  - [ ] Test degradation scenarios

- [ ] **Task 5 (AC: 5):** Setup comprehensive logging
  - [ ] Configure Winston logging for AI operations
  - [ ] Add structured logging for fallback usage
  - [ ] Implement error logging with context
  - [ ] Create performance metrics logging

- [ ] **Task 6 (AC: 1-5):** Testing and validation
  - [ ] Test fallback mechanisms with low confidence
  - [ ] Test error handling with various failure scenarios
  - [ ] Validate health monitoring and alerting
  - [ ] Test graceful degradation and recovery

---

## Dev Notes

### ⚠️ **CRITICAL IMPLEMENTATION NOTE**
**Fallback mechanisms are implemented in n8n workflows, NOT backend services!**

**Implementation Approach:**
- ✅ **Backend API endpoints** - Handle requests and responses
- ✅ **n8n workflows** - Implement fallback logic with rule-based nodes
- ✅ **Database operations** - Store fallback usage and results
- ❌ **DO NOT implement fallback logic in backend services**

**n8n Fallback Strategy:**
- Use Switch nodes for confidence-based routing
- Implement rule-based patterns in n8n
- Use Code nodes for complex fallback logic
- Handle errors with Error Trigger nodes

### Previous Story Insights
**From Story 1.1:**
- Ollama service is accessible at `http://vpn.zopost.vn:11434`
- AI Service module structure is in place
- Database models (AIIntent, AIResponse) are created
- Basic API endpoints are implemented

**From Story 1.2:**
- Intent analysis with confidence scoring is implemented via n8n
- Entity extraction system is working via n8n workflows
- 5-10 intent types are defined and configured
- Confidence thresholds are established

**Key Learnings to Apply:**
- Use established confidence scoring system
- Leverage existing intent type configurations
- Maintain database model relationships
- Follow established error handling patterns

### Data Models
**Enhanced AIIntent Model:**
```prisma
model AIIntent {
  id          String   @id @default(uuid())
  messageId   String   @unique
  intent      String
  confidence  Float
  entities    Json
  context     Json?
  processedAt DateTime @default(now())
  modelVersion String?
  
  // New fields for fallback tracking
  method      String   @default("ai") // "ai" or "rule_based"
  fallbackUsed Boolean @default(false)
  fallbackReason String?
  processingTime Int? // milliseconds
  
  // Relationships
  message     Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)
  responses   AIResponse[]
  
  @@index([intent])
  @@index([confidence])
  @@index([method])
  @@index([fallbackUsed])
  @@index([processedAt])
}
```

**New FallbackLog Model:**
```prisma
model FallbackLog {
  id          String   @id @default(uuid())
  timestamp   DateTime @default(now())
  reason      String   // "low_confidence", "ai_unavailable", "timeout"
  originalIntent String?
  fallbackIntent String
  confidence  Float
  processingTime Int
  context     Json?
  
  @@index([timestamp])
  @@index([reason])
  @@index([fallbackIntent])
}
```

[Source: docs/ai-intent-analysis-strategy.md#fallback-mechanisms]

### API Specifications
**Enhanced POST /api/ai/intent:**
- **Purpose:** Analyze message intent with fallback support
- **Authentication:** Bearer token required
- **Request Body:** Same as Story 1.2
- **Response:** 
  ```json
  {
    "intent": "string",
    "confidence": "float (0.0-1.0)",
    "entities": "object",
    "suggestedActions": ["string"],
    "method": "string", // "ai" or "rule_based"
    "fallbackUsed": "boolean",
    "fallbackReason": "string?",
    "processingTime": "number (ms)"
  }
  ```

**Enhanced GET /api/ai/health:**
- **Purpose:** Comprehensive service health check
- **Authentication:** None required
- **Response:** 
  ```json
  {
    "status": "string", // "healthy", "degraded", "unhealthy"
    "ollama": {
      "status": "string", // "connected", "disconnected", "error"
      "responseTime": "number (ms)",
      "model": "string",
      "lastCheck": "ISO datetime"
    },
    "fallback": {
      "status": "string", // "available", "unavailable"
      "lastUsed": "ISO datetime",
      "usageCount": "number"
    },
    "performance": {
      "averageResponseTime": "number (ms)",
      "requestsPerMinute": "number",
      "errorRate": "float"
    },
    "timestamp": "ISO datetime"
  }
  ```

**New GET /api/ai/fallback-stats:**
- **Purpose:** Get fallback mechanism statistics
- **Authentication:** Bearer token required
- **Response:** 
  ```json
  {
    "totalRequests": "number",
    "aiRequests": "number",
    "fallbackRequests": "number",
    "fallbackRate": "float",
    "reasons": {
      "low_confidence": "number",
      "ai_unavailable": "number",
      "timeout": "number"
    },
    "accuracy": {
      "ai": "float",
      "fallback": "float"
    }
  }
  ```

[Source: docs/backend-architecture.md#rest-api-spec]

### Component Specifications
**Enhanced AI Service (`src/services/ai.service.js`):**
- **Class:** `AIService`
- **Methods:**
  - `analyzeIntentWithFallback(message, context)` - Main method with fallback
  - `shouldUseFallback(confidence, context)` - Fallback decision logic
  - `activateFallback(message, context)` - Activate rule-based analysis
  - `logFallbackUsage(reason, originalIntent, fallbackIntent)` - Log fallback usage
- **Dependencies:** Rule-based analyzer, fallback logger, health monitor

**Rule-Based Fallback Service (`src/services/fallback-analyzer.service.js`):**
- **Class:** `FallbackAnalyzerService`
- **Methods:**
  - `analyzeIntent(message)` - Rule-based intent analysis
  - `matchPatterns(text, patterns)` - Pattern matching
  - `calculateFallbackConfidence(matches)` - Confidence scoring
  - `extractEntities(text, intent)` - Entity extraction
- **Dependencies:** Intent type configuration, pattern matching utilities

**Health Monitoring Service (`src/services/health-monitor.service.js`):**
- **Class:** `HealthMonitorService`
- **Methods:**
  - `checkOllamaHealth()` - Check Ollama service status
  - `getPerformanceMetrics()` - Collect performance data
  - `checkFallbackStatus()` - Verify fallback system status
  - `triggerAlert(condition, message)` - Trigger alerts for failures
- **Dependencies:** Ollama client, metrics collector, alerting system

**Fallback Logger Service (`src/services/fallback-logger.service.js`):**
- **Class:** `FallbackLoggerService`
- **Methods:**
  - `logFallback(reason, originalIntent, fallbackIntent, context)` - Log fallback usage
  - `getFallbackStats(timeframe)` - Get fallback statistics
  - `getFallbackReasons()` - Get breakdown of fallback reasons
  - `exportFallbackLogs(startDate, endDate)` - Export fallback logs
- **Dependencies:** Prisma client, Winston logger

[Source: docs/backend-architecture.md#components]

### File Locations
**New Files to Create:**
- `src/services/fallback-analyzer.service.js` - Rule-based fallback system
- `src/services/health-monitor.service.js` - Health monitoring service
- `src/services/fallback-logger.service.js` - Fallback logging service
- `src/middleware/ai-error-handler.js` - AI-specific error handling
- `src/utils/pattern-matcher.js` - Pattern matching utilities
- `src/config/fallback-rules.js` - Fallback rule configuration

**Files to Modify:**
- `src/services/ai.service.js` - Add fallback logic
- `src/controllers/ai.controller.js` - Add health monitoring endpoints
- `src/app.js` - Add error handling middleware
- `prisma/schema.prisma` - Add fallback tracking fields

[Source: docs/backend-architecture.md#source-tree]

### Testing Requirements
**Unit Tests:**
- Test fallback decision logic with various confidence levels
- Test rule-based pattern matching accuracy
- Test error handling for different failure scenarios
- Test health monitoring and alerting

**Integration Tests:**
- Test complete fallback pipeline
- Test graceful degradation scenarios
- Test service recovery after failures
- Test performance under various conditions

**Test Coverage Target:** >85% for new fallback and error handling code

**Test Scenarios:**
- AI service unavailable
- Low confidence responses
- Network timeouts
- Invalid input handling
- Service recovery

[Source: docs/backend-architecture.md#test-strategy]

### Technical Constraints
**Fallback System:**
- **Activation Threshold:** Confidence <50% triggers fallback
- **Fallback Accuracy:** Must maintain >60% accuracy
- **Response Time:** Fallback must complete within 1 second
- **Coverage:** Must handle all 5-10 intent types

**Error Handling:**
- **Timeout:** 30 seconds for Ollama requests
- **Retries:** 3 attempts with exponential backoff
- **Graceful Degradation:** System must remain functional
- **Recovery:** Automatic recovery when possible

**Health Monitoring:**
- **Check Frequency:** Every 30 seconds
- **Alert Thresholds:** Configurable per metric
- **Performance Metrics:** Response time, throughput, error rate
- **Logging:** Structured logging for all operations

[Source: docs/ai-intent-analysis-strategy.md#error-handling]

---

## Testing

### Test Cases

**Unit Tests:**
- [ ] Fallback system activates at correct confidence threshold
- [ ] Rule-based analysis maintains accuracy requirements
- [ ] Error handling works for all failure scenarios
- [ ] Health monitoring reports correct status
- [ ] Fallback logging captures all required information
- [ ] Pattern matching identifies intent correctly

**Integration Tests:**
- [ ] Complete fallback pipeline works end-to-end
- [ ] Graceful degradation maintains user experience
- [ ] Service recovery works automatically
- [ ] Performance monitoring tracks all metrics
- [ ] Alerting system triggers for critical failures

**Manual Tests:**
- [ ] Test with AI service unavailable
- [ ] Test with low confidence responses
- [ ] Verify fallback accuracy with sample messages
- [ ] Check health monitoring dashboard
- [ ] Test error handling with invalid input

---

## Dev Agent Record

### Completion Notes
*To be filled by Dev Agent during implementation*

### Debug Log
*To be filled by Dev Agent during implementation*

### Change Log
*To be filled by Dev Agent during implementation*

---

## QA Results
*To be filled by QA Agent during review*

---

## Project Structure Notes

**Alignment Status:** ✅ **FULLY ALIGNED**

**Project Structure Verification:**
- ✅ Fallback services follow `src/services/` pattern
- ✅ Error handling middleware follows `src/middleware/` pattern
- ✅ Utility files follow `src/utils/` pattern
- ✅ Configuration files follow `src/config/` pattern
- ✅ API endpoints follow existing REST pattern
- ✅ Database models follow existing Prisma pattern

**No structural conflicts identified.** Story implementation follows established project patterns exactly.

---

## Dependencies

**Internal Dependencies:**
- Story 1.1 must be completed (Ollama service, AI models, basic API)
- Story 1.2 must be completed (Intent analysis, confidence scoring)
- Existing Express app structure
- Existing Prisma database setup
- Existing authentication middleware

**External Dependencies:**
- Pattern matching libraries
- Health monitoring utilities
- Alerting system components

**Dependency Status:** ✅ **READY** - All internal dependencies from Stories 1.1 and 1.2 are satisfied.

---

## Risk Assessment

**Risk Level:** MEDIUM

**Potential Risks:**
1. **Fallback accuracy below 60%** - Mitigation: Extensive testing with real messages
2. **Performance degradation during fallback** - Mitigation: Optimize pattern matching
3. **Complex error handling logic** - Mitigation: Use proven error handling patterns

**Risk Mitigation Status:** ✅ **ADDRESSED**

---

## Definition of Done

- [ ] Rule-based fallback system is implemented and tested
- [ ] Fallback maintains >60% accuracy for all intent types
- [ ] Comprehensive error handling covers all failure scenarios
- [ ] Health monitoring system is operational
- [ ] Graceful degradation works during AI outages
- [ ] Fallback usage is logged and tracked
- [ ] Performance metrics are collected and reported
- [ ] Unit tests passing with >85% coverage
- [ ] Integration tests passing
- [ ] Error handling scenarios tested
- [ ] Documentation updated
- [ ] Code reviewed and approved

---

*Story created using BMAD-METHOD™ framework*
