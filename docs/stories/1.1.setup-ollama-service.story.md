# Story 1.1: Setup Ollama service and basic AI integration

**Epic:** 1 - AI Core Infrastructure  
**Story:** 1.1  
**Status:** Draft  
**Priority:** High  
**Estimate:** 3 days  
**Assigned To:** TBD  

---

## Story

**As a** system administrator,  
**I want** the Ollama AI service to be running and accessible,  
**so that** the system can perform intent analysis on user messages.

---

## Acceptance Criteria

1. **Ollama Service Setup**
   - Ollama Docker container is running and accessible
   - Service responds to health check requests
   - Basic model (llama2:7b) is loaded and ready

2. **AI Service Module**
   - AI Service module is created with basic structure
   - Ollama client utility is implemented
   - Service can connect to Ollama and perform basic operations

3. **Database Integration**
   - AI Intent and AI Response models are added to Prisma schema
   - Database migration is created and applied
   - Basic CRUD operations work for AI models

4. **API Endpoints**
   - `POST /api/ai/intent` endpoint is implemented
   - `GET /api/ai/health` endpoint is implemented
   - Endpoints return appropriate HTTP status codes

5. **Error Handling**
   - Service gracefully handles Ollama unavailability
   - Appropriate error messages are returned
   - Logging is implemented for debugging

---

## Tasks / Subtasks

- [ ] **Task 1 (AC: 1, 2):** Setup Ollama Docker container and configuration
  - [ ] Add Ollama service to docker-compose.yml
  - [ ] Configure environment variables for Ollama connection
  - [ ] Test Ollama container startup and health
  - [ ] Load llama2:7b model in Ollama

- [ ] **Task 2 (AC: 2):** Create AI Service module structure
  - [ ] Create `src/services/ai.service.js` file
  - [ ] Implement basic service class with constructor
  - [ ] Add service to Express app routing
  - [ ] Create service index file for exports

- [ ] **Task 3 (AC: 2):** Implement Ollama client utility
  - [ ] Create `src/utils/ollama-client.js` file
  - [ ] Implement HTTP client for Ollama API calls
  - [ ] Add timeout and retry logic
  - [ ] Implement health check method

- [ ] **Task 4 (AC: 3):** Add AI models to database schema
  - [ ] Add AIIntent model to `prisma/schema.prisma`
  - [ ] Add AIResponse model to `prisma/schema.prisma`
  - [ ] Create and run database migration
  - [ ] Test database operations

- [ ] **Task 5 (AC: 4):** Implement API endpoints
  - [ ] Create `src/controllers/ai.controller.js`
  - [ ] Implement `POST /api/ai/intent` endpoint
  - [ ] Implement `GET /api/ai/health` endpoint
  - [ ] Add routes to Express app

- [ ] **Task 6 (AC: 5):** Add error handling and logging
  - [ ] Implement try-catch blocks in service methods
  - [ ] Add Winston logging for AI operations
  - [ ] Handle Ollama service unavailability
  - [ ] Return appropriate HTTP error responses

- [ ] **Task 7 (AC: 1-5):** Testing and validation
  - [ ] Write unit tests for AI service methods
  - [ ] Test API endpoints with Postman/curl
  - [ ] Verify error handling scenarios
  - [ ] Test database operations

---

## Dev Notes

### ⚠️ **CRITICAL IMPLEMENTATION NOTE**
**Ollama Service is ALREADY DEPLOYED at:** `http://vpn.zopost.vn:11434`

**DO NOT implement local Ollama service!** Instead:
- ✅ **Connect to existing Ollama** at `http://vpn.zopost.vn:11434`
- ✅ **Use n8n workflows** for AI processing (not backend services)
- ✅ **Backend only handles** API endpoints and database operations
- ✅ **AI logic runs in n8n** with Ollama integration

### Previous Story Insights
No previous stories exist - this is the first story of Epic 1.

### Data Models
**AIIntent Model:**
```prisma
model AIIntent {
  id          String   @id @default(uuid())
  messageId   String   @unique
  intent      String
  confidence  Float
  entities    Json
  context     Json?
  processedAt DateTime @default(now())
  modelVersion String?
  
  // Relationships
  message     Message  @relation(fields: [messageId], references: [id], onDelete: Cascade)
  responses   AIResponse[]
  
  @@index([intent])
  @@index([processedAt])
}
```

**AIResponse Model:**
```prisma
model AIResponse {
  id           String   @id @default(uuid())
  intentId     String
  responseType String
  content      String   @db.Text
  actions      Json
  status       String   @default("pending")
  createdAt    DateTime @default(now())
  processedAt  DateTime?
  
  // Relationships
  intent       AIIntent @relation(fields: [intentId], references: [id], onDelete: Cascade)
  executions   WorkflowExecution[]
  
  @@index([status])
  @@index([createdAt])
}
```

[Source: docs/backend-architecture.md#database-schema]

### API Specifications
**POST /api/ai/intent:**
- **Purpose:** Analyze message intent using AI
- **Authentication:** Bearer token required
- **Request Body:** 
  ```json
  {
    "messageId": "uuid",
    "text": "string",
    "context": {
      "channelId": "uuid",
      "senderId": "string",
      "conversationId": "uuid"
    }
  }
  ```
- **Response:** 
  ```json
  {
    "intent": "string",
    "confidence": "float (0.0-1.0)",
    "entities": "object",
    "suggestedActions": ["string"]
  }
  ```

**GET /api/ai/health:**
- **Purpose:** Check AI service health status
- **Authentication:** None required
- **Response:** 
  ```json
  {
    "status": "healthy",
    "ollama": "connected",
    "model": "llama2:7b",
    "timestamp": "ISO datetime"
  }
  ```

[Source: docs/backend-architecture.md#rest-api-spec]

### Component Specifications
**AI Service Module (`src/services/ai.service.js`):**
- **Class:** `AIService`
- **Methods:**
  - `analyzeIntent(message, context)` - Main intent analysis
  - `generateResponse(intent, context)` - Generate AI response
  - `checkHealth()` - Service health check
- **Dependencies:** Ollama client, Prisma client, Winston logger

**Ollama Client (`src/utils/ollama-client.js`):**
- **Class:** `OllamaClient`
- **Methods:**
  - `generate(prompt, options)` - Generate AI response
  - `health()` - Check Ollama service health
  - `listModels()` - List available models
- **Configuration:** Base URL, timeout, retry logic

[Source: docs/backend-architecture.md#components]

### File Locations
**New Files to Create:**
- `src/services/ai.service.js` - AI service module
- `src/utils/ollama-client.js` - Ollama client utility
- `src/controllers/ai.controller.js` - AI API controller
- `prisma/migrations/YYYYMMDDHHMMSS_add_ai_models.sql` - Database migration

**Files to Modify:**
- `src/app.js` - Add AI routes
- `prisma/schema.prisma` - Add AI models
- `docker-compose.yml` - Add Ollama service

[Source: docs/backend-architecture.md#source-tree]

### Testing Requirements
**Unit Tests:**
- Test AI service methods with mocked Ollama client
- Test error handling scenarios
- Test database operations with test database

**Integration Tests:**
- Test API endpoints with real Ollama service
- Test database migrations and operations
- Test service health checks

**Test Coverage Target:** >80% for new AI service code

[Source: docs/backend-architecture.md#test-strategy]

### Technical Constraints
**Ollama Configuration:**
- **Base URL:** `http://ollama:11434/api`
- **Model:** `llama2:7b` (default)
- **Timeout:** 30 seconds
- **Retries:** 3 attempts with exponential backoff

**Database Constraints:**
- **MessageId:** Must be unique (one intent per message)
- **Confidence:** Float between 0.0 and 1.0
- **Context:** JSON field for flexible metadata

**Performance Requirements:**
- **Response Time:** <2 seconds for intent analysis
- **Throughput:** Support 100 requests/day
- **Error Rate:** <5% for successful requests

[Source: docs/backend-architecture.md#external-apis]

---

## Testing

### Test Cases

**Unit Tests:**
- [ ] AI Service constructor initializes correctly
- [ ] analyzeIntent method calls Ollama client
- [ ] generateResponse method works with valid input
- [ ] checkHealth method returns correct status
- [ ] Error handling for Ollama unavailability
- [ ] Database operations for AI models

**Integration Tests:**
- [ ] API endpoints respond correctly
- [ ] Database migrations apply successfully
- [ ] Ollama service integration works
- [ ] Error responses have correct HTTP status codes

**Manual Tests:**
- [ ] Docker container starts and runs
- [ ] API endpoints accessible via Postman/curl
- [ ] Database models created correctly
- [ ] Logging shows appropriate information

---

## Dev Agent Record

### Completion Notes
*To be filled by Dev Agent during implementation*

### Debug Log
*To be filled by Dev Agent during implementation*

### Change Log
*To be filled by Dev Agent during implementation*

---

## QA Results
*To be filled by QA Agent during review*

---

## Project Structure Notes

**Alignment Status:** ✅ **FULLY ALIGNED**

**Project Structure Verification:**
- ✅ AI Service location matches `src/services/` pattern
- ✅ Ollama Client location matches `src/utils/` pattern  
- ✅ AI Controller location matches `src/controllers/` pattern
- ✅ Database models follow existing Prisma schema pattern
- ✅ API endpoints follow existing REST API pattern
- ✅ Docker service follows existing docker-compose pattern

**No structural conflicts identified.** Story implementation follows established project patterns exactly.

---

## Dependencies

**External Dependencies:**
- Ollama Docker image (`ollama/ollama:latest`)
- llama2:7b model download (first run)

**Internal Dependencies:**
- Existing Express app structure
- Existing Prisma database setup
- Existing authentication middleware
- Existing logging configuration

**No blocking dependencies identified.** Story can be implemented immediately.

---

## Risk Assessment

**Risk Level:** LOW

**Potential Risks:**
1. **Ollama model download time** - Mitigation: Use smaller model initially
2. **Docker container startup issues** - Mitigation: Test on target environment
3. **Database migration conflicts** - Mitigation: Review existing schema carefully

**Risk Mitigation Status:** ✅ **ADDRESSED**

---

## Definition of Done

- [ ] Ollama container running and accessible
- [ ] AI Service module implemented and tested
- [ ] Database models created and migrated
- [ ] API endpoints working and tested
- [ ] Error handling implemented and tested
- [ ] Unit tests passing with >80% coverage
- [ ] Integration tests passing
- [ ] Documentation updated
- [ ] Code reviewed and approved

---

*Story created using BMAD-METHOD™ framework*
